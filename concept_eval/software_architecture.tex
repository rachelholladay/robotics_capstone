% !TEX root = main.tex

\pagebreak
\section{Software Architecture}
\label{sec:software_architecture}
The software architecture can be separated into three sections: image processing, work planning and distribution, and communication between robot onboard systems and the central offboard system. These systems are described below.

\subsection{Image Processing}
\label{sec:sw_arch_image_processing}

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.99\columnwidth]{diagrams/sw_arch_image_processing.jpg}
	\caption{Image Processing Software Pipeline}
 \label{fig:image_processing}
\end{figure}

The image processing pipeline (\figref{fig:image_processing}) takes the image scanned by the user, and parses it into a form readable by the work planner. The goal of this software system is to create a series of lines that describes the image. To do this, the system first creates an occupancy grid of the input via voxelization. For a black and white image, the occupancy grid determines black or white. In the case of color, voxels are assigned color based on the image values inside of the voxel.

Once voxelization is complete, lines are formed from the voxels through a nearest-neighbor search. These lines are simply a series of voxel squares that pass through the image. In order to preserve curvature of lines from the input, the grid-delineated lines are reparamterized with splines into paths. These paths are then sent to the work planning module.

\subsection{Communication}
\label{sec:sw_arch_communication}

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.99\columnwidth]{diagrams/sw_arch_communication.jpg}
	\caption{Communication Software Pipeline}
 \label{fig:comm_processing}
\end{figure}

The communication diagram (\figref{fig:comm_processing}) describes how an individual robot communicates with the offboard path planning system. The system can be described by communciation in four categories: motion commands, writing tool commands, error handling, and localization.

The offboard system will use the planning algorithm to determine motion plans for the robot systems. It determines and then sends velocity commands to the onboard system. The onboard system passes these commands to the drive motors for motion.

To command the writing tool, the offboard system also decides how to move the writing implement based on localization of the robot systems. Similar to velocity commands, the onboard system receives commands for the writing tool, and commands the system accordingly.

Localization receives input from the sensor module, and computes position and orientation. This data is then sent back to the central offboard module to update planning and scheduling.

Error logs are generated by the offboard system based on localization and planning, and sent to each robot's onboard system for appropriate reaction. This includes the emergency stop, which will immediately shut down writing tool and drive motors.

\subsection{Work Scheduling, Distribution and Planning}
\label{sec:sw_arch_planner}

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.99\columnwidth]{diagrams/sw_arch_planning.jpg}
	\caption{Planning and Scheduling Software Pipeline}
 \label{fig:planning_processing}
\end{figure}

A key aspect of our software system is distributing and planning the work to the robot agents, modeled in \figref{fig:planning_processing}.
Two of our nonfunctional requirements are to be efficient and have the robots coordinate with each other (NFR4, NFR9). These two objectives inform our planning pipeline. We split the planning and coordination into two separate problems, allowing us to frame coordination as a scheduling problem~\cite{o1989deadlock}. Hence our work distribution and planning can be handled offline while our coordinate occurs online. 

From our image processing \sref{sec:sw_arch_image_processing}, we recieve processed image data. 
Using this data, we compute the length of every individual line. 
Guided by the assumption that line length correlates to amount of work done and the time to perform that work, we then use those lengths to load balance when assigning which lines should be drawn by each robot. 
Once each line has been assigned to each robot, each robot has a complete picture of their work and assign an ordering to their lines. 
To limit wasteful movement, the robots order lines greedily: having completed one lines, they pick their next lines (from their assigned set) based on which line has the closet endpoint to the lines they have just finished. 
Having ordered lines, we now can determine each robot's set of paths. 

Next, we briefly describe a sketch of our coordination mechanism. Each robot has a queue of paths, based on the set ordering, to execute.
Given that a robot has not finished all of it's assigned paths, it removes a path from the queue.
The path is then uniformly timed and converted into a trajectory.
Given timing information, the system can check for path collision between any trajectories currently being executed.
If the trajectory is not at risk of collision, then it can be executed - and is sent to the robot via the protocol mentioned in \sref{sec:sw_arch_communication}. 

If the trajectory is in collision with a currently executing trajectory, then the trajectory being processed defers to the one being executed. 
The timing of the processing trajectory is adjusted by adding a pause to avoid collision. Given this modified timing we can then execute it. 

Once all paths have been drawn, the drawing is completed.

