% !TEX root = main.tex

\section{Localization}
\label{sec:localization}
The localization system uses an overhead camera and marker (\sref{sec:trade_localization}) to determine a robot's position and orientation. It uses an overhead-mounted camera with a full, unobstructed view of the workspace and the robot agents. Static markers are mounted in the corners of the workspace, as well as atop the robot workers themselves. The corner markers determine the boundaries of the workspace, to which the input image can be scaled. The system use the robot-mounted markers to determine the position and orientation of each robot in relation to the workspace. It then communicates the positions and orientations of the robots to the scheduling module (\sref{sec:planning}). This module directly satisfies local and global localization requirements, as well as indirectly allows for safe and bounded motion from the robots (Requirements Specification, 5.1, \frref{fr:localize}, \frref{fr:in_bounds}). \\

\noindent
\textbf{Critical Components:} Localization algorithm, localization markers.

\deleted[remark={DZ, V2}]{The environmental markers must be set up by the user before the system can begin drawing. The continuously output pings using both an infared light and ultrasonic transmitter. In doing so, they provide the data needed by the localization subsystem (\sref{sec:localization}) to determine the robot's position and orientation in the workspace. They will be mounted high enough as to be visible by every robot in the workspace at all times. \\}

\deleted[remark={DZ, V2}]{The sensor module gathers data from environmental markers (\sref{sec:localization}). This data is used by the localization module (\sref{sec:localization}) to determine an individual robot's position and orientation in the workspace. \\}

\subsection{Use Cases}
\subsubsection{Localize}
\textbf{Description:} \added[remark={DZ, V2}]{The robot uses a combination of robot-mounted and static environmental markers, as well as a camera mounted above the working surface to determine the locations of each of the robots. This information is used to determine the motion plan of the robot.}

\subsection{Trade Study}
\label{sec:trade_localization}
In multi-agent planning, it is important to accurately localize robots' positions and orientations. Keeping in mind limitations in price and ease of use, we come up with two major methods for localization: vision based and marker based. They are described below.

Vision-based localization involves using cameras or other visual sensors to directly obtain information of the environment and localize the robots based on found landmarks in that environment. One example of this is SLAM (Simultaneous Localization and Mapping), often used by autonomous vehicles to simultaneously build maps and localize~\cite{dissanayake2001solution}. With this approach, robots could build small maps of their surroundings and match their locations to features they find in the environment. Benefits of this method include being location agnostic and requiring no additional parts or external setup. Pure vision systems are difficult to calibrate and localization accuracy can depend heavily on static surroundings, but this is relatively easy to guarantee given the requirements of the system (Requirements Specification, 2.3, 2.4 A1).

The other choice of methodology is marker based. Using markers placed around the drawing surface, robot agents can quickly locate these markers and their positions relative to each marker, and consequently triangulate their positions and orientations. While requiring additional setup and more parts to calibrate than vision based localization, existing technology makes it convenient and cheap to get marker based localization working. One example of a marker-based localization system is AprilTags~\cite{olson2011apriltag}, which can be described as 2D barcodes placed in a scene. Marker-based localization can be further classified into two subcategories: passive and active. Passive markers do not output any information and exist for the robot agents to observe and triangulate accordingly. AprilTags is an example of the passive marker system. On the other hand, active markers will ``look at" robot agents to determine where the agents are, rather than the robots searching for markers. While less common, active systems behave well in conditions when the markers may not always be easily visible to robot agents~\cite{cassinis2005active}.

\added[remark={DZ, V2}]{Given the convenience and ease of use of marker-based localization, it is clearly the better choice. Additionally, since the workspace is limited to an indoor, flat, and homogenous area in our requirements specification (Requirements Specification, 2.3, 2.4 A1) we can reliably count on overhead line-of-sight as opposed to having the robots observe or be observed by the passive or active markers. An indoor space also allows for easy mounting of an overhead camera. Consequently, we have decided to pursue a passive marker system observed from above by a single camera.}

\subsection{Artistic Sketch}

\begin{figure}[!ht]
 \centering
  \includegraphics[width=0.95\columnwidth]{sketches/Localization.jpg} 
	\caption{Localization Sketch}
 \label{fig:localization_sketch}
\end{figure}
\clearpage

\subsection{Requirements Fulfilled}
\added[remark={RH, V2}]{Our localization system allows the robot to be autonomous (\frref{fr:autonomous}) and localize (\frref{fr:localize}), which gives them the information to stay within workspace boundaries (\frref{fr:in_bounds}). Our localization will be refined to account for error handling (\nfrref{nfr:errors}). Precision in localization will enable our robot to produce a quality image (\nfrref{nfr:quality}) with positional (\nfrref{nfr:pos_accuracy}) and rotational accuracy (\nfrref{nfr:rot_accuracy}) that is coordinated with the rest of the system (\nfrref{nfr:coordination}). As we continue with our overhead camera system we will develop reliability (\nfrref{nfr:reliability}) and safety (\nfrref{nfr:safe}) into the system. We believe that our simple overhead camera will be within budget (\nfrref{nfr:budget}).}
